{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A01_MNIST_noTensorflow.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ycl3JfN_pAD6",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# 텐서플로우 없이 풀어보는 딥러닝"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BO7rE6O5JiRG",
        "colab_type": "text"
      },
      "source": [
        "## 편미분과 오차역전파 선택\n",
        "\n",
        "편미분 : 1\n",
        "\n",
        "오차역전파 : 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4vEpafuo4Mf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 오차역전파와 미분함수 중 선택\n",
        "# process = (미분사용 : 1 , 역전파사용 : 2)\n",
        "\n",
        "process = 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6Dp-FCjJrqS",
        "colab_type": "text"
      },
      "source": [
        "## MNIST 데이터 가져오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJGE-zp3rW4j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import time\n",
        "from keras.datasets import mnist\n",
        "\n",
        "(x_train, t_train), (x_test, t_test) = mnist.load_data()\n",
        "t_trainlbl, t_testlbl = t_train, t_test\n",
        "\n",
        "# 28X28 을 784 로 변환\n",
        "# x_train = x_train.reshape(60000,784)    # 28*28 을 784로 변환\n",
        "# x_test = x_test.reshape(10000,784)    \n",
        "x_train = x_train.reshape(-1,784)    # 28*28 을 784로 변환\n",
        "x_test = x_test.reshape(-1,784)    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8beNJ3ODevP-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a6c6f37e-64ed-4011-de83-fc4a2efb44f4"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jJFPl4bMbG3",
        "colab_type": "text"
      },
      "source": [
        "## 원핫 레이블 준비"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RslWEkWZKeB3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7cc3cce8-58de-4ff2-c429-07316857d6e0"
      },
      "source": [
        "# one-hot label \n",
        "T0 = np.zeros((t_train.size, 10))    #(60000,10) = 000...\n",
        "T1 = np.zeros((t_test.size, 10))    #(10000,10) = 000...\n",
        "\n",
        "for idx in range(t_train.size): T0[idx][t_train[idx]] = 1   \n",
        "for idx in range(t_test.size): T1[idx][t_test[idx]] = 1\n",
        "\n",
        "t_train, t_test = T0, T1\n",
        "\n",
        "# normalize 0.0 ~ 1.0\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "print('MNIST DataSets 준비 완료')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MNIST DataSets 준비 완료\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-uld0KAQvlS",
        "colab_type": "text"
      },
      "source": [
        "## 함수정의 : 수치미분"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50hxeoihrRe6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 함수 정의 : 수치미분, 소프트맥스, CEE\n",
        "\n",
        "# 미분함수 \n",
        "def numerical_diff(f, x):\n",
        "    h = 1e-4    # 0.0001\n",
        "    nd_coef = np.zeros_like(x)\n",
        "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
        "    while not it.finished:\n",
        "        index = it.multi_index\n",
        "        tmp = float(x[index])\n",
        "        x[index] = tmp + h\n",
        "        fxh2 = f()    # f(x+h)\n",
        "        x[index] = tmp - h \n",
        "        fxh1 = f()    # f(x-h)\n",
        "        nd_coef[index] = (fxh2 - fxh1) / (2*h)\n",
        "        x[index] = tmp \n",
        "        it.iternext()\n",
        "    return nd_coef\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wt66jRUCQ5RX",
        "colab_type": "text"
      },
      "source": [
        "## 소프트맥스"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62f-wBtdQ0bg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 소프트맥스\n",
        "def softmax(x):\n",
        "    if x.ndim == 1:  # 기본 1개 처리과정 , 벡터입력\n",
        "        x = x - np.max(x) \n",
        "        return np.exp(x) / np.sum(np.exp(x))\n",
        "    if x.ndim == 2:  # 배치용 n 개 처리, 행렬입력\n",
        "        x = x.T - np.max(x.T, axis=0)\n",
        "        return (np.exp(x) / np.sum(np.exp(x), axis=0)).T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3w6RocFQ2to",
        "colab_type": "text"
      },
      "source": [
        "## 크로스엔트로피"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jxi98cB7Q16o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 크로스엔트로피오차\n",
        "def cee(y, t):\n",
        "    if y.ndim == 1:\n",
        "        t = t.reshape(1, t.size)  # 크기가 1xN 인 2차원 행렬로 재구성\n",
        "        y = y.reshape(1, y.size)\n",
        "    result = -np.sum(t * np.log(y + 1e-7)) / y.shape[0]\n",
        "    return result "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpknvV-RQ87C",
        "colab_type": "text"
      },
      "source": [
        "## 클래스정의 : Relu, Affine, SoftmaxWithLoss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPM_52X0rN5N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 클래스 정의 : ReLU, Affine, SoftmaxWithLoss, \n",
        "\n",
        "class Relu:\n",
        "    def __init__(self):\n",
        "        self.mask = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.mask = (x <= 0)\n",
        "        result = x.copy()\n",
        "        result[self.mask] = 0\n",
        "        return result\n",
        "\n",
        "    def backward(self, dout):\n",
        "        dout[self.mask] = 0\n",
        "        dx = dout\n",
        "        return dx\n",
        "\n",
        "class Affine:\n",
        "    def __init__(self, W, b):\n",
        "        self.W = W    # W0, W1\n",
        "        self.b = b    # b0, b1\n",
        "        self.x = None\n",
        "        self.dW = None    # W0, W1 의 기울기\n",
        "        self.db = None    # b0, b1 의 기울기\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.x = x\n",
        "        result = np.dot(self.x, self.W) + self.b\n",
        "        return result\n",
        "\n",
        "    def backward(self, dout):\n",
        "        dx = np.dot(dout, self.W.T)\n",
        "        self.dW = np.dot(self.x.T, dout)\n",
        "        self.db = np.sum(dout, axis=0)\n",
        "        return dx\n",
        "\n",
        "class SoftmaxWithLoss:\n",
        "    def __init__(self):\n",
        "        self.y = None    # 출력(계산결과)\n",
        "        self.t = None    # 정답(MNIST레이블)\n",
        "        \n",
        "    def forward(self, x, t):\n",
        "        self.t = t\n",
        "        self.y = softmax(x)\n",
        "        result = cee(self.y, self.t)\n",
        "        return result\n",
        "\n",
        "    def backward(self, dout=1):\n",
        "        batch_size = self.t.shape[0]\n",
        "        dx = (self.y - self.t) / batch_size\n",
        "        return dx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dF4pHf8fRIo3",
        "colab_type": "text"
      },
      "source": [
        "## 클래스 정의 : SimpleNetwork\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRX6fx0oqo1a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 클래스 정의 : SimpleNetwork\n",
        "\n",
        "class SimpleNetwork:\n",
        "    def __init__(self, inputx, hidden, outy, weight):\n",
        "        # 가중치 초기화\n",
        "        self.netMat = {}\n",
        "        self.netMat['W0'] = weight * np.random.randn(inputx, hidden)\n",
        "        self.netMat['b0'] = np.zeros(hidden)\n",
        "        self.netMat['W1'] = weight * np.random.randn(hidden, outy) \n",
        "        self.netMat['b1'] = np.zeros(outy)\n",
        "\n",
        "        # 계층 생성\n",
        "        self.netLayers = {}\n",
        "        self.netLayers['Affine1'] = Affine(self.netMat['W0'], \n",
        "                                           self.netMat['b0'])\n",
        "        self.netLayers['Relu1'] = Relu()\n",
        "        self.netLayers['Affine2'] = Affine(self.netMat['W1'], \n",
        "                                           self.netMat['b1'])\n",
        "        self.netLayers['Softmax'] = SoftmaxWithLoss()\n",
        "\n",
        "    def predict(self, x):\n",
        "        x = self.netLayers['Affine1'].forward(x)\n",
        "        x = self.netLayers['Relu1'].forward(x)\n",
        "        x = self.netLayers['Affine2'].forward(x)\n",
        "        return x\n",
        "        \n",
        "    # x : 입력 데이터, t : 정답 레이블\n",
        "    def loss(self, x, t):\n",
        "        y = self.predict(x)\n",
        "        return self.netLayers['Softmax'].forward(y, t)\n",
        "    \n",
        "    def accuracy(self, x, t):\n",
        "        y = self.predict(x)\n",
        "        y = np.argmax(y, axis=1)\n",
        "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
        "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
        "        return accuracy\n",
        "        \n",
        "    def numerical_gradient(self, x, t):\n",
        "        lossfunc = lambda : self.loss(x, t)\n",
        "        grads = {}\n",
        "        grads['W0'] = numerical_diff(lossfunc, self.netMat['W0'])\n",
        "        grads['b0'] = numerical_diff(lossfunc, self.netMat['b0'])\n",
        "        grads['W1'] = numerical_diff(lossfunc, self.netMat['W1'])\n",
        "        grads['b1'] = numerical_diff(lossfunc, self.netMat['b1'])\n",
        "        return grads\n",
        "        \n",
        "    def gradient(self, x, t):\n",
        "        # forward\n",
        "        self.loss(x, t)\n",
        "\n",
        "        # backward\n",
        "        dout = 1\n",
        "        dout = self.netLayers['Softmax'].backward(dout)\n",
        "        dout = self.netLayers['Affine2'].backward(dout)\n",
        "        dout = self.netLayers['Relu1'].backward(dout)\n",
        "        dout = self.netLayers['Affine1'].backward(dout)\n",
        "\n",
        "        # 기울기(dW, db) 저장\n",
        "        grads = {}\n",
        "        grads['W0'] = self.netLayers['Affine1'].dW \n",
        "        grads['b0'] = self.netLayers['Affine1'].db\n",
        "        grads['W1'] = self.netLayers['Affine2'].dW \n",
        "        grads['b1'] = self.netLayers['Affine2'].db\n",
        "        return grads\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taczyE6QRMCi",
        "colab_type": "text"
      },
      "source": [
        "## 설정치 입력"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2Ahz-BZq1TC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 학습을 위한 설정치 입력\n",
        "\n",
        "train_size = x_train.shape[0]\n",
        "lr = 0.1\n",
        "iter = 0\n",
        "\n",
        "# 미분을 사용할 경우 :: 배치 20, 1000회 반복 \n",
        "# (20개 묶음 데이터로 1000번 학습진행)\n",
        "if process == 1:\n",
        "    iters_num = 1000\n",
        "    batch_size = 20\n",
        "    iter_per_epoch = 1\n",
        "\n",
        "# 역전파사용 : 배치 100, 60000회 반복\n",
        "# 100개 묶음 데이터로 60000 회 학습진행\n",
        "else :\n",
        "    iters_num = 60000\n",
        "    batch_size = 100\n",
        "    iter_per_epoch = int(train_size / batch_size)    # 600\n",
        "\n",
        "# MNIST 입력(784), 은닉층(노드 50개), 출력층(노드 10개)\n",
        "network = SimpleNetwork(inputx=784, hidden=50, outy=10, weight = 0.2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7TJeRDZRPr8",
        "colab_type": "text"
      },
      "source": [
        "## 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkrNeDO4q_1F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 학습과 검증 \n",
        "\n",
        "# 시간측정 시작\n",
        "t1 = time.time()\n",
        "print('loss = _______  time = ________  n = ______ | [TrainAcc] [TestAcc]')\n",
        "\n",
        "for i in range(iters_num):   \n",
        "    batch_mask = np.random.choice(train_size, batch_size)    # 60000 개중 100 개\n",
        "    x_batch = x_train[batch_mask]    \n",
        "    t_batch = t_train[batch_mask]\n",
        "    \n",
        "    # 기울기 계산\n",
        "\n",
        "    if process==1:\n",
        "        grad = network.numerical_gradient(x_batch, t_batch) # 수치 미분 방식\n",
        "    else:\n",
        "        grad = network.gradient(x_batch, t_batch) # 오차역전파법 방식(훨씬 빠르다)\n",
        "    \n",
        "    # 위에서 만들어진 기울기로 W 와 b 갱신\n",
        "    for key in ('W0', 'b0', 'W1', 'b1'):\n",
        "        network.netMat[key] -=  lr * grad[key] \n",
        "    \n",
        "    loss = network.loss(x_batch, t_batch)\n",
        "    # train_loss_list.append(loss)\n",
        "\n",
        "    if i % iter_per_epoch == 0:\n",
        "        train_acc = network.accuracy(x_train, t_train)\n",
        "        test_acc = network.accuracy(x_test, t_test)\n",
        "        iter = iter + 1\n",
        "        print('loss = {:7.4f}  '.format(loss), end='')\n",
        "        print('time = {:8.4f}  '.format(time.time()-t1), end='')    \n",
        "        print('n = {:06d} |{:8.4f}{:11.4f}'.format(iter, train_acc, test_acc))\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}