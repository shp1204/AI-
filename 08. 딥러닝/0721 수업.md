

# 1. 텐서플로우

: 딥러닝 프레임워크

![image-20200721141014055](0721%20%EC%88%98%EC%97%85.assets/image-20200721141014055.png)

```python
import tensorflow as tf
a = tf.constant (10)
b = tf.constant (32)
sess1 = tf.Session ()
print (sess1.run (a+b))
```

```python
import tensorflow as tf
x = tf.constant(35, name=‘x’)
y = tf.Variable(x+5,name=‘y’)
model = tf.global_variables_initializer()
with tf.Session() as session:
session.run(model)
print(session.run(y))
```

```
텐서플로우 2.0
• 편리성 향상
• Keras와 즉시 실행(Eager execution)을 이용한 쉬운 모델 작성
• 어떤 플랫폼에서든 튼튼한(Robust) 모델 배포
• Deprecated된 API를 정리하고 중복을 줄여서 API 단순화
```

1 ) 즉시 실행(Eager execution)

```
• Eager execution은 그래프 생성 없이 연산을 즉시 실행
• 실행할 계산 그래프 없이 실제 값을 얻는 것 가능
• 직관적인 인터페이스
• 쉬운 디버깅
```

2 ) keras API 지원

: 텐서플로우는 그래프 기반 모델 설계, keras는 레이어들 선형으로 쌓는 sequential 모델

3 ) 튼튼한 모델 배포

![image-20200721141910425](0721%20%EC%88%98%EC%97%85.assets/image-20200721141910425.png)



# 2. 신경망 및 퍼셉트론

![image-20200721142745344](0721%20%EC%88%98%EC%97%85.assets/image-20200721142745344.png)

![image-20200721142959058](0721%20%EC%88%98%EC%97%85.assets/image-20200721142959058.png)

```
x : input
w : weight
b : bias ( 0 또는 값 )
f = x*w +b, activation 함수(y를 도출하기 위한 조건)
y : 0 ~ 1 사이의 값
```

![image-20200721144005439](0721%20%EC%88%98%EC%97%85.assets/image-20200721144005439.png)

선형적인 문제는 해결이 가능하다. 그렇다면 비선형적 문제는 ? 해결할 수 없다.

==========> AI 1차 겨울

그렇다면 다층 퍼셉트론으로 문제를 해결하자.

# 3. 다층 퍼셉트론 (MLP)

hidden layer가 많아질수록 더 세분화된 분리가 가능하게 된다.

```
* 문제점 *
1 ) 연산량이 너무 많다 : parameter(bias, weight)
2 ) vanishing gradient 문제 : sigmoid function을 사용하면 미분값이 1보다 작아지게 된다 => back propagation시, 1보다 작은 값을 계속 곱할 경우 0에 수렴해지기 때문에 문제 발생
3 ) overfitting의 위험성 증가
```

==========> AI 2차 겨울

vanishing 문제 해결 : 미분값이 1보다 작지 않게 하자 . relu함수 사용

미분을 계속하더라도 미분값의 업데이트가 가능해진다.



![sigmoid](0721%20%EC%88%98%EC%97%85.assets/image-20200721150653389.png)

![image-20200721150725491](0721%20%EC%88%98%EC%97%85.assets/image-20200721150725491.png)

* Leaky Relu : 0보다 작은 경우, 신경이 죽어버리는 현상 극복
* Tanh : 함수값의 범위가 (-1, 1), 도함수의 최댓값이 1



