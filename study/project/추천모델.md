# 방법

1) Matrix Factorization (MF) : eigen vector, svd로 전체적인거 

```
User 와 Item의 Interaction을 Matrix로 표현한 다음 Factorize하여 Latent Vector를 얻습니다.
```

:  재생횟수, 클릭수, 좋아요를 눌렀는지 여부 등등

2) Factorization Machine (FM)

```
다양한 Feature들 간의 Interaction을 Polynomial Rergression으로 모델링합니다.
```

feature가 다양한 데이터셋에 좋은 모델이고 CTR예측 대회에서 좋은 성과를 얻음

3) Multi-Armed Bandit (MAB)

```
한정된 정보로 학습을 해가며 Regret을 줄이고 최적의 Arm을 찾습니다.
```

4) Deep Learning

```
Task와 Data 구조에 맞게 적절한 DL 모델을 변형, 적용합니다.
```

5) Reinforcement Learning (RL)

```
장기적인 유저의 만족도를 Reward로 삼아 다양한 콘텐츠를 추천합니다.
```



---------

# 추천 방법론

## 콘텐츠 기반 필터링

: 

## 협업 필터링

: 다른 사람들이 들은 곡을 바탕으로 어떤 곡들이 서로 비슷한지를 알아내는 방법

* 행렬분해(Matrix Factorization)

  ![image-20200715134525261](C:%5CUsers%5C%EB%B0%95%EC%86%8C%ED%9D%AC%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20200715134525261.png)

행렬 곱을 계산한 매트릭스가 원래의 매트릭스와 비슷하게 나오도록하는 것이다. 이 과정에서 원래 유저가 소비하지 않았던 곡들에 대한 숫자들이 나오는데, 이 숫자들을 유저에 대한 해당 곡의 선호도라고 할 수 있따.

* 오토인코더 

  얘는 몽타주와 비슷한 것이다. 행렬분해와 비슷하게 입력 데이터를 원래의 차원보다 더 적은 데이터로 줄인 후에, 변환한 데이터를 기반으로 원래의 데이터를 복원하는 구조로 되어있다. 원본 데이터가 그대로 복원되기 보다는 원본에서 가장 중요한 핵심 갓들이 나오는 방식이다. 

* 디노이징 오토인코더

  만약 트레이닝 과정에서 노이즈가 발생하면, 노이즈 낀 인풋을 가지고 원본을 복원하며 태스크를 수행하는 오토인코더를 디노이징 오토인코더라고 한다.

## 하이브리드 : 콘텐츠 + 협업



-----

참고 : https://www.facebook.com/groups/2611614312273351/permalink/2662015087233273

[https://kutar37.tistory.com/entry/%ED%8C%8C%EC%9D%B4%EC%8D%AC-%ED%98%91%EC%97%85%ED%95%84%ED%84%B0%EB%A7%81Collaborative-Filtering-%EC%B6%94%EC%B2%9C-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98-1](https://kutar37.tistory.com/entry/파이썬-협업필터링Collaborative-Filtering-추천-알고리즘-1)

----------

content vs item

collaborative : 함축적 행동을 갖고 추천, 영역의 구애 x, profile 자체에 편향이 생길 수 있기 때문에 좋은 성향 but cold start problem 

- neighborhood : 아이템-user

  

MF : SVD 가 missing value에 약하기 때문에 ( 새로운 장르를 인지하지 못함 / 유저가 평가하지 않은 경우 ) regulization modeling으로 한다. probabilitic matrix factorization을 진행하고있따.

explicit vs implicit

-------

MAB : https://sumniya.tistory.com/9

강화학습에 많이 사용되고, A/B 테스트보다 좋음

exploitation : 경험에 의존

exploration : 도전

regret  (error) : 내가 기대한 것 - 실제 결과

```
* greedy : 지금 당장 내가 많이 벌 수 있는 것 ( 경험적으로 )
=> 문제 : exploration을 고려할 수 없음

* e-greedy : (1 - ε)의 확률로 기존에 관측한 값을 중 가장 좋은 머신을 선택
=> exploration, exploitation 둘 다 고려함
=> 문제 : 시행이 반복되면 optimal 한 값으로 수렴하고, 이때 문제 발생

* UCB : 초반에는 exploration에 가중치를 많이 두고, 많이 수행할 수록 exploitation에 가중치를 많이 두게 된다
=> 시간이 지나면 경험적인 데이터에 많이 영향 줌 ㅇㅇ
=> 많이 안돌리면 안 좋아

--- UCB 까지는 cold start problem 이 존재한다 ---

* Thompson Sampling

```

