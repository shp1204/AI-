{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 최적화 기법과 Greedy 알고리즘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 목표\n",
    "- 최적화 기법이 왜 필요하고 무엇인지 학습합니다.\n",
    "- Greedy 알고리즘을 구현하고 그 문제점을 파악합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 목차"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 최적화 기법\n",
    "1. 최적화 기법이란?\n",
    "\n",
    "### 2. Greedy 알고리즘\n",
    "1. Greedy 알고리즘 정의\n",
    "2. Greedy 알고리즘 문제점\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 최적화 기법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1. 최적화 기법이란?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1장에서는 간단한 형태인 단순 선형 회귀 방식에 대해서 학습하였습니다.\n",
    "\n",
    "단순 선형 회귀는 1차 함수 형태의 근사선 모델을 사용하여 1개의 feature 종류에 따른 label의 관계를 분석했습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 단순 선형 회귀 모델 \n",
    "\n",
    "> $$f(x_i)=w_O+w_1 x_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서 우리는 학습 과정으로 하이퍼 파라미터 $w_0, w_1$을 튜닝하여 loss 값을 최소로 만들었습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 최소값 문제\n",
    "\n",
    "> $$\\min_{w_0,w_1}Loss(w_0, w_1)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 최소값 문제를 해결하는 방법으로 1장에서는 least square라는 방법을 사용해서 해결할 수 있었습니다.\n",
    "\n",
    "least square 좋은 해결책이였지만 최소값을 푸는 방법은 다양한 방식이 존재합니다.\n",
    "\n",
    "이러한 최소값 또는 최대값 문제를 해결하는 방법들을 최적화 기법이라 합니다. \n",
    "\n",
    "수 많은 과학자, 수학자, 공학자들이 다양한 방법을 제안해왔고, 각 방식들은 장단점을 갖기에 한 가지 방식만을 고집하여 쓸 필요가 없습니다.\n",
    "\n",
    "따라서 2장에서는 2가지 중요한 최적화 기법인 Greedy 알고리즘과 Gradient descent 알고리즘을 학습하여 최적화 기법의 선택 폭을 넓힐 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Greedy 알고리즘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1. Greedy 알고리즘 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최소 or 최대 값을 구하는 방식으로 greedy 알고리즘은 지금 환경의 모든 경우를 고려하여 최소 or 최대 값을 찾는 방식을 의미합니다.\n",
    "\n",
    "만일 모델링한 1차 함수의 기울기가 $[0.1,0.2,...,1]$, y절편은 $[0.1,0.2,...,1]$로 각각 10개의 값만을 갖는다고 가정해 봅시다.\n",
    "\n",
    "그렇다면 우리가 얻을 수 있는 Loss 함수 값은 총 100개가 될 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Greedy 예시\n",
    "\n",
    "> $$Loss(기울기=0.1, y절편=0.1), \\\\ Loss(기울기=0.1, y절편=0.2),\\\\ Loss(기울기=0.1, y절편=0.3),\\\\ \\vdots \\\\ Loss(기울기=0.2, y절편=0.1), \\\\ \\vdots \\\\ Loss(기울기=1, y절편=1)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100개의 Loss 값들을 계산하며 낮은 값이 나올때마다 최소 값을 갱신해 나가는 방식으로 최소 값을 구합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/1-1-1.png\" width=\"30%\" height=\"30%\" title=\"greedy1\" alt=\"greedy1\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 예에서는 기울기 0.3과 y절편 0.1을 가정 했을 때 가장 낮은 loss 값을 갖는 것을 구할 수 있었습니다.\n",
    "\n",
    "다소 무식해보이는 방식이지만 자동으로 연산을 해주는 컴퓨터가 있기에 범위만 잡아주게 되면 최소 값을 찾을 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <예제 1> greedy 알고리즘을 사용항 최적화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1장 단순 선형 회귀에서 수행했던 데이터와 모델을 가져와 greedy 알고리즘을 사용하여 최적의 파라미터를 구해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_0: 0.1, w_1: 0.1, loss: 36.5925\n",
      "\n",
      "w_0: 0.1, w_1: 0.2, loss: 33.3625\n",
      "\n",
      "w_0: 0.1, w_1: 0.30000000000000004, loss: 30.2825\n",
      "\n",
      "w_0: 0.1, w_1: 0.4, loss: 27.352500000000003\n",
      "\n",
      "w_0: 0.1, w_1: 0.5, loss: 24.5725\n",
      "\n",
      "w_0: 0.1, w_1: 0.6, loss: 21.942500000000006\n",
      "\n",
      "w_0: 0.1, w_1: 0.7000000000000001, loss: 19.4625\n",
      "\n",
      "w_0: 0.1, w_1: 0.8, loss: 17.132499999999997\n",
      "\n",
      "w_0: 0.1, w_1: 0.9, loss: 14.9525\n",
      "\n",
      "w_0: 0.1, w_1: 1.0, loss: 12.922500000000001\n",
      "\n",
      "w_0: 0.2, w_1: 0.1, loss: 35.4675\n",
      "\n",
      "w_0: 0.2, w_1: 0.2, loss: 32.2875\n",
      "\n",
      "w_0: 0.2, w_1: 0.30000000000000004, loss: 29.2575\n",
      "\n",
      "w_0: 0.2, w_1: 0.4, loss: 26.377500000000005\n",
      "\n",
      "w_0: 0.2, w_1: 0.5, loss: 23.6475\n",
      "\n",
      "w_0: 0.2, w_1: 0.6, loss: 21.067500000000003\n",
      "\n",
      "w_0: 0.2, w_1: 0.7000000000000001, loss: 18.637500000000003\n",
      "\n",
      "w_0: 0.2, w_1: 0.8, loss: 16.3575\n",
      "\n",
      "w_0: 0.2, w_1: 0.9, loss: 14.2275\n",
      "\n",
      "w_0: 0.2, w_1: 1.0, loss: 12.247500000000002\n",
      "\n",
      "w_0: 0.30000000000000004, w_1: 0.1, loss: 34.36250000000001\n",
      "\n",
      "w_0: 0.30000000000000004, w_1: 0.2, loss: 31.2325\n",
      "\n",
      "w_0: 0.30000000000000004, w_1: 0.30000000000000004, loss: 28.2525\n",
      "\n",
      "w_0: 0.30000000000000004, w_1: 0.4, loss: 25.4225\n",
      "\n",
      "w_0: 0.30000000000000004, w_1: 0.5, loss: 22.742500000000007\n",
      "\n",
      "w_0: 0.30000000000000004, w_1: 0.6, loss: 20.212500000000006\n",
      "\n",
      "w_0: 0.30000000000000004, w_1: 0.7000000000000001, loss: 17.8325\n",
      "\n",
      "w_0: 0.30000000000000004, w_1: 0.8, loss: 15.602500000000001\n",
      "\n",
      "w_0: 0.30000000000000004, w_1: 0.9, loss: 13.5225\n",
      "\n",
      "w_0: 0.30000000000000004, w_1: 1.0, loss: 11.592500000000003\n",
      "\n",
      "w_0: 0.4, w_1: 0.1, loss: 33.2775\n",
      "\n",
      "w_0: 0.4, w_1: 0.2, loss: 30.197500000000005\n",
      "\n",
      "w_0: 0.4, w_1: 0.30000000000000004, loss: 27.267500000000005\n",
      "\n",
      "w_0: 0.4, w_1: 0.4, loss: 24.4875\n",
      "\n",
      "w_0: 0.4, w_1: 0.5, loss: 21.8575\n",
      "\n",
      "w_0: 0.4, w_1: 0.6, loss: 19.377500000000005\n",
      "\n",
      "w_0: 0.4, w_1: 0.7000000000000001, loss: 17.0475\n",
      "\n",
      "w_0: 0.4, w_1: 0.8, loss: 14.867500000000003\n",
      "\n",
      "w_0: 0.4, w_1: 0.9, loss: 12.837500000000002\n",
      "\n",
      "w_0: 0.4, w_1: 1.0, loss: 10.957500000000001\n",
      "\n",
      "w_0: 0.5, w_1: 0.1, loss: 32.212500000000006\n",
      "\n",
      "w_0: 0.5, w_1: 0.2, loss: 29.1825\n",
      "\n",
      "w_0: 0.5, w_1: 0.30000000000000004, loss: 26.302500000000002\n",
      "\n",
      "w_0: 0.5, w_1: 0.4, loss: 23.572500000000005\n",
      "\n",
      "w_0: 0.5, w_1: 0.5, loss: 20.992500000000003\n",
      "\n",
      "w_0: 0.5, w_1: 0.6, loss: 18.5625\n",
      "\n",
      "w_0: 0.5, w_1: 0.7000000000000001, loss: 16.2825\n",
      "\n",
      "w_0: 0.5, w_1: 0.8, loss: 14.1525\n",
      "\n",
      "w_0: 0.5, w_1: 0.9, loss: 12.172500000000003\n",
      "\n",
      "w_0: 0.5, w_1: 1.0, loss: 10.342500000000001\n",
      "\n",
      "w_0: 0.6, w_1: 0.1, loss: 31.167500000000004\n",
      "\n",
      "w_0: 0.6, w_1: 0.2, loss: 28.1875\n",
      "\n",
      "w_0: 0.6, w_1: 0.30000000000000004, loss: 25.3575\n",
      "\n",
      "w_0: 0.6, w_1: 0.4, loss: 22.677500000000002\n",
      "\n",
      "w_0: 0.6, w_1: 0.5, loss: 20.1475\n",
      "\n",
      "w_0: 0.6, w_1: 0.6, loss: 17.767500000000002\n",
      "\n",
      "w_0: 0.6, w_1: 0.7000000000000001, loss: 15.537500000000001\n",
      "\n",
      "w_0: 0.6, w_1: 0.8, loss: 13.457499999999998\n",
      "\n",
      "w_0: 0.6, w_1: 0.9, loss: 11.527500000000002\n",
      "\n",
      "w_0: 0.6, w_1: 1.0, loss: 9.747500000000002\n",
      "\n",
      "w_0: 0.7000000000000001, w_1: 0.1, loss: 30.142500000000005\n",
      "\n",
      "w_0: 0.7000000000000001, w_1: 0.2, loss: 27.212500000000002\n",
      "\n",
      "w_0: 0.7000000000000001, w_1: 0.30000000000000004, loss: 24.432499999999997\n",
      "\n",
      "w_0: 0.7000000000000001, w_1: 0.4, loss: 21.802500000000002\n",
      "\n",
      "w_0: 0.7000000000000001, w_1: 0.5, loss: 19.3225\n",
      "\n",
      "w_0: 0.7000000000000001, w_1: 0.6, loss: 16.992500000000003\n",
      "\n",
      "w_0: 0.7000000000000001, w_1: 0.7000000000000001, loss: 14.812500000000002\n",
      "\n",
      "w_0: 0.7000000000000001, w_1: 0.8, loss: 12.782499999999999\n",
      "\n",
      "w_0: 0.7000000000000001, w_1: 0.9, loss: 10.902500000000002\n",
      "\n",
      "w_0: 0.7000000000000001, w_1: 1.0, loss: 9.1725\n",
      "\n",
      "w_0: 0.8, w_1: 0.1, loss: 29.137500000000003\n",
      "\n",
      "w_0: 0.8, w_1: 0.2, loss: 26.257500000000004\n",
      "\n",
      "w_0: 0.8, w_1: 0.30000000000000004, loss: 23.527500000000003\n",
      "\n",
      "w_0: 0.8, w_1: 0.4, loss: 20.9475\n",
      "\n",
      "w_0: 0.8, w_1: 0.5, loss: 18.517500000000005\n",
      "\n",
      "w_0: 0.8, w_1: 0.6, loss: 16.237500000000004\n",
      "\n",
      "w_0: 0.8, w_1: 0.7000000000000001, loss: 14.1075\n",
      "\n",
      "w_0: 0.8, w_1: 0.8, loss: 12.127500000000001\n",
      "\n",
      "w_0: 0.8, w_1: 0.9, loss: 10.2975\n",
      "\n",
      "w_0: 0.8, w_1: 1.0, loss: 8.617500000000003\n",
      "\n",
      "w_0: 0.9, w_1: 0.1, loss: 28.152500000000003\n",
      "\n",
      "w_0: 0.9, w_1: 0.2, loss: 25.3225\n",
      "\n",
      "w_0: 0.9, w_1: 0.30000000000000004, loss: 22.642500000000005\n",
      "\n",
      "w_0: 0.9, w_1: 0.4, loss: 20.112500000000004\n",
      "\n",
      "w_0: 0.9, w_1: 0.5, loss: 17.7325\n",
      "\n",
      "w_0: 0.9, w_1: 0.6, loss: 15.502500000000001\n",
      "\n",
      "w_0: 0.9, w_1: 0.7000000000000001, loss: 13.422500000000001\n",
      "\n",
      "w_0: 0.9, w_1: 0.8, loss: 11.4925\n",
      "\n",
      "w_0: 0.9, w_1: 0.9, loss: 9.712500000000002\n",
      "\n",
      "w_0: 0.9, w_1: 1.0, loss: 8.082500000000001\n",
      "\n",
      "w_0: 1.0, w_1: 0.1, loss: 27.1875\n",
      "\n",
      "w_0: 1.0, w_1: 0.2, loss: 24.407500000000002\n",
      "\n",
      "w_0: 1.0, w_1: 0.30000000000000004, loss: 21.7775\n",
      "\n",
      "w_0: 1.0, w_1: 0.4, loss: 19.297500000000003\n",
      "\n",
      "w_0: 1.0, w_1: 0.5, loss: 16.9675\n",
      "\n",
      "w_0: 1.0, w_1: 0.6, loss: 14.787500000000001\n",
      "\n",
      "w_0: 1.0, w_1: 0.7000000000000001, loss: 12.757499999999999\n",
      "\n",
      "w_0: 1.0, w_1: 0.8, loss: 10.877500000000001\n",
      "\n",
      "w_0: 1.0, w_1: 0.9, loss: 9.1475\n",
      "\n",
      "w_0: 1.0, w_1: 1.0, loss: 7.567500000000001\n",
      "\n",
      "Minimum Loss: 7.567500000000001 when w_0: 1.0, w_1: 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# feature, label 데이터 선언\n",
    "feature_data = np.array([1,2,3,4])\n",
    "label_data = np.array([3.1, 4.9, 7.2, 8.9])\n",
    "\n",
    "\n",
    "# 1차 선형 모델 함수 정의\n",
    "def linear_model(w_0, w_1, feature_data):\n",
    "    f_x = w_0 + w_1*feature_data\n",
    "    return f_x\n",
    "\n",
    "# loss 함수 정의\n",
    "def loss(f_x, label_data):\n",
    "    error = label_data - f_x\n",
    "    ls = np.mean(error**2)\n",
    "    return ls\n",
    "\n",
    "# 최소 loss값을 저장할 변수 초기화\n",
    "min_loss_f_x = 100000\n",
    "\n",
    "# greedy 알고리즘 시작\n",
    "for i in np.arange(0.1, 1.1, 0.1):\n",
    "    for j in np.arange(0.1, 1.1, 0.1):\n",
    "        \n",
    "        # 1차 선형 함수 출력값 저장\n",
    "        f_x = linear_model(i,j,feature_data)\n",
    "        \n",
    "        # 1차 선형 함수의 loss 값 저장\n",
    "        loss_f_x = loss(f_x,label_data)\n",
    "        print(\"w_0: {}, w_1: {}, loss: {}\\n\".format(i,j,loss_f_x))\n",
    "        \n",
    "        # 최소 loss 값을 저장\n",
    "        if (loss_f_x < min_loss_f_x):\n",
    "            min_loss_f_x = loss_f_x\n",
    "            min_w_0 = i\n",
    "            min_w_1 = j\n",
    "            \n",
    "# 최소 loss 값 출력\n",
    "print(\"Minimum Loss: {} when w_0: {}, w_1: {}\".format(min_loss_f_x,min_w_0, min_w_1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2. Greedy 알고리즘 문제점"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그렇다면 greedy 알고리즘의 문제점은 무엇일까요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. 무한 범위에서의 계산 불가능**\n",
    "\n",
    "아래 그림과 같이 실수 범위(무한)에서의 기울기, y 절편에 해당되는 Loss 값들은 비교가 불가능합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/1-1-2.png\" width=\"30%\" height=\"30%\" title=\"greedy2\" alt=\"greedy2\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. 특정 범위에만 한정된 최소 값을 구할 수 있음**\n",
    "\n",
    "항상 특정 범위를 설정하여 기울기, y절편에 해당되는 Loss 값들 비교해야 합니다. 그렇기에 범위를 벗어 난 곳에 더 작은 값이 있을 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/1-1-3.png\" width=\"30%\" height=\"30%\" title=\"greedy3\" alt=\"greedy3\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. 범위 내의 모든 값을 비교하기에 계산양이 매우 많음**\n",
    "\n",
    "항상 특정 범위를 설정하여 기울기, y절편에 해당되는 Loss 값들 비교해야 합니다. 그렇기에 범위를 벗어 난 곳에 더 작은 값이 있을 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
