{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 목표\n",
    "- Logistic Regresssion을 이해하고, Scikit-learn과 NumPy로 구현할 수 있다.\n",
    "- Titanic 데이터를 사용하여 Binary Classification (1: Survived, 0: Not Survived)를 구현할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 목차\n",
    "\n",
    "### 2.1. Logistic Regression - Scikit Learn\n",
    "1. 데이터 로드\n",
    "2. 모델 정의\n",
    "3. 모델 학습 (with Train data)\n",
    "4. 결과 예측 (with Test data)\n",
    "5. 결과 평가\n",
    "\n",
    "### 2.2. Logistic Regression - NumPy\n",
    "1. 데이터 로드\n",
    "2. 모델 정의\n",
    "3. 모델 학습 (with Train data)\n",
    "4. 결과 예측 (with Test data)\n",
    "5. 결과 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1  Logistic Regression - Scikit-Learn (Titanic)\n",
    "\n",
    "> Scikit-Learn을 사용하여 로지스틱 회귀를 실습해봅니다.\n",
    "- 사용할 데이터: 외부에서 가져온 titanic 데이터\n",
    "- Logistic Regression과 Softmax Regression은 Sklearn의 linear_model 패키지에 있는LogisticRegression 메서드를 사용가능합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1-1. 데이터 로드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Titanic 데이터를 불러올 Load_Dataset 함수를 구현합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T06:32:10.186778Z",
     "start_time": "2020-07-13T06:32:10.178771Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv                           # 데이터 파일 로드\n",
    "import numpy as np                   # numpy 행렬 조작을 위해\n",
    "\n",
    "np.random.seed(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T06:32:11.742886Z",
     "start_time": "2020-07-13T06:32:11.732882Z"
    }
   },
   "outputs": [],
   "source": [
    "def Load_Dataset(filename):\n",
    "\n",
    "    with open(filename, 'r') as f:\n",
    "        csv_reader = csv.reader(f)                  # 파일 로드\n",
    "        header = next(csv_reader)\n",
    "\n",
    "        x_data = []\n",
    "        y_data = []\n",
    "        for line in csv_reader:\n",
    "            features = line[1:]\n",
    "            x = [1] + list(map(float, features))    # x_data에 bias를 위한 1추가\n",
    "            y = float(line[0])\n",
    "\n",
    "            x_data.append(x)\n",
    "            y_data.append(y)\n",
    "\n",
    "        x_array = np.array(x_data)\n",
    "        y_array = np.array(y_data)\n",
    "\n",
    "    return header, x_array, y_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T06:32:14.875109Z",
     "start_time": "2020-07-13T06:32:14.853094Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(779, 7)\n",
      "(108, 7)\n"
     ]
    }
   ],
   "source": [
    "_, x_train, y_train = Load_Dataset('data/Titanic_train.csv')\n",
    "_, x_test, y_test = Load_Dataset('data/Titanic_test.csv')\n",
    "\n",
    "# shape을 확인합니다. (데이터개수 X feature 개수)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1-2. 모델 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-Learn에 구현된 LogisticRegression 함수를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T06:32:24.874215Z",
     "start_time": "2020-07-13T06:32:20.597176Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(fit_intercept=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1-3. 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T06:32:28.570843Z",
     "start_time": "2020-07-13T06:32:28.488785Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=False,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1-4. 결과 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T06:32:32.060323Z",
     "start_time": "2020-07-13T06:32:32.053321Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1.\n",
      " 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0.\n",
      " 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "y_pred = lr.predict(x_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1-5. 결과 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일반적으로 분류에서는 `Accuracy (정확도)`를 평가 척도로 사용합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T06:32:41.043708Z",
     "start_time": "2020-07-13T06:32:41.037703Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로지스틱 회귀, 정확도 : 83.33%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('로지스틱 회귀, 정확도 : {:.2f}%'.format(accuracy_score(y_test, y_pred)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2  Logistic Regression - NumPy (Titanic)\n",
    "\n",
    "> NumPy을 사용하여 로지스틱 회귀를 직접 구현해봅니다.\n",
    "- 사용할 데이터: 외부에서 가져온 titanic 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2-1. 데이터 로드\n",
    "\n",
    "이전과 동일하므로 생략합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os                            # 데이터 파일 경로 설정\n",
    "import csv                           # 데이터 파일 로드\n",
    "import numpy as np                   # numpy 행렬 조작\n",
    "import matplotlib.pyplot as plt      # 그래프 그리기(선택 사항)\n",
    "\n",
    "np.random.seed(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2-2. 모델 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.   __\\_\\_init\\_\\___\n",
    "\n",
    "\n",
    "> *   인자: 모델 설정 \n",
    "*   출력: x\n",
    "*   기능: 모델 초기화\n",
    "\n",
    "> weight *W*를 random하게 initialization\n",
    "\n",
    "2.   __train__\n",
    "\n",
    "\n",
    "> *   입력: 학습데이터, 학습 설정\n",
    "*   출력: Loss \n",
    "*   기능: 데이터로 모델 학습\n",
    "\n",
    "> 매 epoch마다 전체 데이터에 대해 loss, gradient 계산하여 학습\n",
    "\n",
    "\n",
    "3. __predict__\n",
    "\n",
    "> *   입력: 검증 데이터\n",
    "*   출력: 모델의 예측값\n",
    "*   기능: train로 학습된 모델로 검증, 예측값 생성\n",
    "\n",
    "> 검증 데이터에 대해 분류 예측 결과 산출 \n",
    "\n",
    "4. ___sigmoid__\n",
    "\n",
    "> *   입력: 실수형 numpy array\n",
    "*   출력: sigmoid를 취한 array\n",
    "*   기능: 주어진 array에 대한 모든 sigmoid 값 계산\n",
    "\n",
    "> $sigmoid(x) =\\frac{1}{ 1+e^{-(x)}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "  def __init__(self, num_features):\n",
    "    self.W = np.random.rand(num_features, 1) * 0.01\n",
    "\n",
    "  def train(self, train_x, train_y, num_epochs, learning_rate):\n",
    "    loss_memory = []\n",
    "    train_y = np.expand_dims(train_y, 1)\n",
    "\n",
    "    # ================ 아래에 코드를 작성해주세요 =================\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "      # 1-1. hypothesis 계산\n",
    "      hypothesis = None        # np.matmul 사용\n",
    "\n",
    "      # 1-2. sigmoid 적용\n",
    "      prob = self._sigmoid(hypothesis)\n",
    "\n",
    "      # 1-3. Error 및 Loss 계산\n",
    "      error = None              # prob에서 train_y를 뺀 값\n",
    "      loss = None\n",
    "\n",
    "      # 1-4. Loss ‘loss_memory’에 추가\n",
    "      loss_memory.append(loss)\n",
    "\n",
    "      # 1-5. Gradient 계산\n",
    "      grad = np.mean(train_x * error, axis=0, keepdims=True).T\n",
    "\n",
    "      # 1-6. Weight Update\n",
    "      self.W = None             # grad와 learning_rate를 사용\n",
    "\n",
    "    # ===============================================================\n",
    "    return loss_memory\n",
    "\n",
    "  def predict(self, test_x):\n",
    "    # 코드를 작성해주세요        # np.matmul 사용, test_x와 self.W를 사용\n",
    "\n",
    "    return pred\n",
    "\n",
    "  def _sigmoid(self, x):\n",
    "    # 코드를 작성해주세요\n",
    "\n",
    "      return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title 정답 코드\n",
    "class LogisticRegression:\n",
    "  def __init__(self, num_features):\n",
    "      self.W = np.random.rand(num_features, 1) * 0.01\n",
    "\n",
    "  def train(self, train_x, train_y, num_epochs, learning_rate):\n",
    "\n",
    "      loss_memory = []\n",
    "      train_y = np.expand_dims(train_y, 1)\n",
    "\n",
    "      for epoch in range(num_epochs):\n",
    "          # ====================== 아래에 코드를 작성해주세요 ======================\n",
    "          \n",
    "          # 1-1. hypothesis 계산\n",
    "          hypothesis = np.matmul(train_x, self.W)\n",
    "\n",
    "          # 1-2. sigmoid 적용\n",
    "          prob = self._sigmoid(hypothesis)\n",
    "\n",
    "          # 1-3. Error 및 Loss 계산\n",
    "          error = prob - train_y\n",
    "\n",
    "          loss = - np.mean(train_y * np.log(prob) + (1 - train_y) * np.log(1 - prob))\n",
    "          \n",
    "          # print(loss)\n",
    "          # 1-4. Loss ‘loss_memory’에 추가\n",
    "          loss_memory.append(loss)\n",
    "\n",
    "          # 1-5. Gradient 계산\n",
    "          grad = np.mean(train_x * error, axis=0, keepdims=True).T\n",
    "\n",
    "          # 1-6. Weight Update\n",
    "          self.W -= grad * learning_rate\n",
    "          # ==================================================================\n",
    "\n",
    "      # 2. ‘loss_memory’ 반환\n",
    "      return loss_memory\n",
    "\n",
    "  def predict(self, test_x):\n",
    "      prob = self._sigmoid(np.matmul(test_x, self.W))\n",
    "\n",
    "      return prob\n",
    "\n",
    "  def _sigmoid(self, x):\n",
    "      return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2-3. 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameter\n",
    "num_epochs = 1000      # 조정해보세요!\n",
    "learning_rate = 1e-3   # 조정해보세요!\n",
    "\n",
    "# Training\n",
    "header, train_x, train_y = Load_Dataset('data/Titanic_train.csv')\n",
    "num_data, num_features = train_x.shape\n",
    "\n",
    "model = LogisticRegression(num_features)\n",
    "loss_memory = model.train(train_x, train_y, num_epochs, learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2-4. 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Accuracy(prob, true):\n",
    "  Acc = 0\n",
    "  \n",
    "  #Acc 계산\n",
    "  pred = np.round(prob, 0)\n",
    "  correct = np.sum(pred.squeeze() == true)\n",
    "  num_data = pred.shape[0]\n",
    "\n",
    "  Acc = correct / num_data\n",
    "\n",
    "  return Acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  71.29629629629629\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "_, test_x, test_y = Load_Dataset('data/Titanic_test.csv')\n",
    "pred = model.predict(test_x)\n",
    "acc = Accuracy(pred, test_y)\n",
    "\n",
    "print('Accuracy: ', acc*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
